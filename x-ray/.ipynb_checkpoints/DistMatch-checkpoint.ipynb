{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b3d69e-37c0-453e-b422-35d21f1e5f22",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28df967d-86a7-4db8-a319-08359bcda04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_curve, auc, roc_auc_score, classification_report, accuracy_score, silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ba1f4c-2269-48ed-a66f-1eab71ce774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D, Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import Adadelta, Adam, SGD, Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197767cb-3480-4f12-834b-fbdf4757b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "      #  for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e645877-0150-49a8-a960-cf1f45314364",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = './data/new_mimic_train.tfrecords'\n",
    "val_filename = './data/new_mimic_val.tfrecords'\n",
    "test_filename = './data/new_mimic_test.tfrecords'\n",
    "IMAGE_WIDTH, IMAGE_HEIGHT = 256, 256\n",
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 16\n",
    "current_mode = 'mmd'\n",
    "current_group = 'race'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e198a795-72c4-4bb9-bafc-c9abc0a6c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    'jpg_bytes': tf.io.FixedLenFeature([], tf.string),\n",
    "    'race': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'age': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'gender': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'subject_id': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'Cardiomegaly': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'Consolidation': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'Edema': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'Enlarged Cardiomediastinum': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'Lung Opacity': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'Atelectasis': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'No Finding': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'Pleural Effusion': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'Pneumonia': tf.io.FixedLenFeature([], tf.float32),\n",
    "    'Pneumothorax': tf.io.FixedLenFeature([], tf.float32)\n",
    "}\n",
    "\n",
    "label_list = ['Pneumothorax', 'Pneumonia', 'Pleural Effusion', 'No Finding', 'Atelectasis', 'Lung Opacity','Enlarged Cardiomediastinum', 'Edema', 'Consolidation', 'Cardiomegaly']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfb46d1-c89f-4c85-a2fa-5b094297d136",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d49976-e75c-4f85-a9e6-ad24fe386aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse(example):\n",
    "    return tf.io.parse_single_example(example, feature_description)\n",
    "def read_tfrecord(example):\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    img = tf.image.decode_jpeg(example['jpg_bytes'], channels=3)\n",
    "    labels = [tf.cast(0, tf.int64) if example['No Finding'] == 1 else tf.cast(1, tf.int64)]\n",
    "    \n",
    "    if current_group == 'age':\n",
    "        groups = [tf.cast(0, tf.int64) if example['age'] <= 1 else tf.cast(example['age']-1, tf.int64)]\n",
    "    elif current_group == 'race':\n",
    "        groups = [tf.cast(2, tf.int64) if example['race'] == 4 else tf.cast(example['race'], tf.int64)]\n",
    "    else:\n",
    "        groups = [tf.cast(example['gender'], tf.int64)]\n",
    "    return img, labels, groups\n",
    "\n",
    "def _fixup_shape(images, labels, groups):\n",
    "    images.set_shape([IMAGE_HEIGHT,IMAGE_WIDTH, 3])\n",
    "    labels.set_shape([1])\n",
    "    groups.set_shape([1])\n",
    "    return images, labels, groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7046038-d219-46fd-8869-06a9417755e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "    dataset = tf.data.TFRecordDataset(filename)\n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls = tf.data.experimental.AUTOTUNE).map(_fixup_shape)\n",
    "    dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4649d8-88f8-48fb-82d3-b6126ddf064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = load_dataset(train_filename)\n",
    "dataset_val = load_dataset(val_filename)\n",
    "dataset_test = load_dataset(test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550f9ea4-d57b-441e-8a30-e4e14a8a2e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for img, label, domain in dataset_val.take(1):\n",
    "    for n in range(16):\n",
    "        ax = plt.subplot(4, 8, n+1)\n",
    "        plt.imshow(img[n])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4b2fea-90c0-4cfc-ae91-3dbb251a7bc8",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5a3dba-9a84-486b-9ac0-275e86aeccd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, 3)\n",
    "input_img = Input(input_shape)\n",
    "x = tf.keras.applications.densenet.preprocess_input(input_img)\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_tensor = x, pooling = 'avg')\n",
    "x = base_model(x)\n",
    "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=input_img, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16250c7-f021-4586-8d3f-6a43c9dda6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4c4966-7453-428a-ae4d-69465f400d1c",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c24313-6543-4b26-bfef-bce8ffe2b0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.0001)\n",
    "train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')\n",
    "val_accuracy = tf.keras.metrics.BinaryAccuracy(name='val_accuracy')\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_lp_loss')\n",
    "val_loss = tf.keras.metrics.Mean(name='val_lp_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f69386-eeec-4948-bfbf-730310fc9202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cdist(x1, x2):\n",
    "    x1_norm = tf.reduce_sum(tf.math.pow(x1, 2), axis=-1, keepdims=True)\n",
    "    x2_norm = tf.reduce_sum(tf.math.pow(x2, 2), axis=-1, keepdims=True)\n",
    "    \n",
    "    mm = -2*tf.linalg.matmul(x1, tf.transpose(x2, perm=[1, 0]))\n",
    "\n",
    "    madd = tf.math.add(tf.transpose(x2_norm, perm=[1, 0]), mm)\n",
    "\n",
    "    res = tf.math.add(madd, x1_norm)\n",
    "\n",
    "    return tf.clip_by_value(res, clip_value_min=1e-30, clip_value_max=1e30)\n",
    "\n",
    "def gaussian_kernel(x, y, gamma=[0.001, 0.01, 0.1, 1, 10, 100,\n",
    "                                       1000]):\n",
    "    D = my_cdist(x, y)\n",
    "    \n",
    "    K = tf.zeros_like(D)\n",
    "\n",
    "    for g in gamma:\n",
    "        K = tf.math.add(K, tf.math.exp(tf.math.multiply(D, -g)))\n",
    "\n",
    "    return K/len(gamma)\n",
    "\n",
    "def mmd(x, y):\n",
    "    # https://stats.stackexchange.com/questions/276497/maximum-mean-discrepancy-distance-distribution\n",
    "    Kxx = tf.reduce_mean(gaussian_kernel(x, x))\n",
    "    Kyy = tf.reduce_mean(gaussian_kernel(y, y))\n",
    "    Kxy = tf.reduce_mean(gaussian_kernel(x, y))\n",
    "    return Kxx + Kyy - 2 * Kxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7b3d35-6d0d-46cd-8e79-340128043efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if current_group == 'race':\n",
    "    group = [0,1,2]\n",
    "elif current_group == 'age':\n",
    "    group = [0,1,2,3]\n",
    "else:\n",
    "    group = [0,1]\n",
    "    \n",
    "@tf.function\n",
    "def train_step(images, labels, groups, mode='mmd'):\n",
    "    penalty = 0.0\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = model(images)\n",
    "        loss = loss_object(labels, pred)  \n",
    "        for target in group:\n",
    "            mask = groups == target\n",
    "            grp_trg = pred[tf.squeeze(mask)][:,-1]\n",
    "            all_trg = pred[:,-1]\n",
    "            if len(grp_trg) > 0:\n",
    "                if mode == 'mmd':\n",
    "                    penalty +=  mmd(tf.expand_dims(grp_trg, -1), tf.expand_dims(all_trg,-1))\n",
    "                else:\n",
    "                    penalty += tf.math.abs(tf.reduce_mean(grp_trg) -  tf.reduce_mean(pred))\n",
    "        if mode == 'mean':\n",
    "            total_loss = loss + 1*penalty\n",
    "        else:\n",
    "            total_loss = loss + 1*penalty\n",
    "        \n",
    "    grads = tape.gradient(total_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    \n",
    "    train_loss(total_loss)\n",
    "    train_accuracy(labels, pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08cd0df-3dc4-4908-ba98-91c2ed96cd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def val_step(images, labels, domains):\n",
    "    pred = model(images)\n",
    "    loss = loss_object(labels, pred)  \n",
    "    val_loss(loss)\n",
    "    val_accuracy(labels, pred)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a95d4d6-2c49-421a-a89f-0a1914251158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(domain=True):\n",
    "    for batch in tqdm(dataset_val):\n",
    "        val_step(*batch)\n",
    "        \n",
    "def test(domain=True):\n",
    "    for batch in tqdm(dataset_test):\n",
    "        val_step(*batch)\n",
    "\n",
    "def reset_metrics(target):\n",
    "\n",
    "    if target == 'train':\n",
    "        train_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "\n",
    "    if target == 'val':\n",
    "        val_loss.reset_states()\n",
    "        val_accuracy.reset_states()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e56cc7-bb15-4097-8823-e18c8850b88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "prev = 0\n",
    "count = 0\n",
    "for epoch in range(epochs):\n",
    "    for batch in tqdm(dataset_train):\n",
    "        train_step(*batch, mode = current_mode)\n",
    "\n",
    "    print(\"Training: Epoch {} :\\t Accuracy : {:.3%}, loss : {}\"\n",
    "          .format(epoch, train_accuracy.result(), train_loss.result()))\n",
    "    \n",
    "    reset_metrics('train')\n",
    "    \n",
    "    val()\n",
    "    val_acc = val_accuracy.result()\n",
    "    print(\"Val: Accuracy : {:.3%}, loss : {}\"\n",
    "          .format(val_accuracy.result(), val_loss.result()))\n",
    "    \n",
    "    if val_acc > prev:\n",
    "        prev = val_acc\n",
    "        print('save acc: {}'.format(val_acc))\n",
    "        model.save_weights(\"./model/\" + current_mode + \"/distmatch_\" + current_group)\n",
    "        count = 1\n",
    "    else:\n",
    "        count += 1\n",
    "    \n",
    "    if count > 10:\n",
    "        break\n",
    "        \n",
    "    reset_metrics('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d085d843-967f-4307-a464-a25b2ecf6651",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
